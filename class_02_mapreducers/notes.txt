wget http://media.sundog-soft.com/hadoop/ml-100k/u.data
wget http://media.sundog-soft.com/hadoop/RatingsBreakdown.py
wget http://media.sundog-soft.com/hadoop/TopMovies.py

hdfs dfs -copyFromLocal u.data /user/maria_dev/u.data
python RatingsBreakdown.py -r hadoop --hadoop-streaming-jar /usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar hdfs:///user/maria_dev/u.data
python RatingsTotalCount.py -r hadoop --hadoop-streaming-jar /usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar hdfs:///user/maria_dev/u.data
python TopMovies.py -r hadoop --hadoop-streaming-jar /usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar hdfs:///user/maria_dev/u.data


*** HDFS
- optimized for handling big files. It breaks those files into blocks (128 megabytes by default). You can store files that are bigger then a individual harddrive can store. In this manner hadoop allows the distributed processing of these large files.
- it has a single name node and this name node is what keep track of where all those blocks alive. It has an “edit log” that maintains a record of what is being created, what is being modified and what is being stored.
- there are some manners to avoid a single point of failure on a name node (which must be unique – except for name node federation)
  - back up metadata: name nodes writes to local disks and NFS.
  - secondary namenode: maintains merged copy of edit log you can restore from
  - hdfs federation: each namenode manages a specific namespace volume
  - hdfs high availability: hot standby namenode using shared edit log, zoodeeper tracks active namenode, uses extreme measures to ensure only one namenode is used at a time (like cut power off).
- How to use HDFS?
  - UI (Ambari)
  - Command Line Interface 
  - HTTP / HDFS Proxies
  - Java interface
  - NFS Gateway

*** MapReduce
- MapReduce is one of the core pieces of hadoop.
- Distributes the processing of your data on your cluster.
- Divides you data up into partitions that are Mapped (transformed) and Reduced (Aggregated) by mapper and reducer funcions you define.
- Resilient to failure - an application master monitor your mappers and reducers on each partition. 
- Reduce -> Aggregate data