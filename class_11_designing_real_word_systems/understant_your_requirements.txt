WORKING BACKWARDS
- Start with the end user's needs, not from where your data is coming from.
  - Sometimes you need to meet in the middle.
- What sorts of access patterns do you antecipate from your end users
  - Analytical queries that span large data ranges?
  - Huge amounts of small transactions for very specific rows of data?
  - Both?
- What availability do these users demand?
- What consistency do these users demand?
THINKING ABOUT REQUIREMENTS
- Just how big is your big data?
  - Do you really need a cluster?
- How much internal infrastructure and expertise is available?
  - Should you use AWS or something similar?
  - Do systems you already know fit the bill?
- What about data retentions?
  - Do you need to keep data around foreverfor auditing?
  - Or do you need to purge it often, for privacy?
- What about security?
  - Check with legal

LATENCY
- How quicly do end users need to get a response?
  - Milliseconds? Maybe HBase or Cassandra will be needed
- Timeless
  - Can queries be based on day-old data? Minute-old?
    - Oozie scheduled jobs in Hive/Pig/Spark/etc may cut it.
  - Or must be near real time?
    - Use Spark Streaming/Storm/Flink with Kafka/Flume

JUDICIOUS FUTURE-PROOFING
- Once you decide to store your "big data", movint it will be really dificulty later on.
  - Think carefully before choosing proprietary solutions or cloud-based storage.
- Will business analysts want your data in adition to end users? (or vice-versa?)

CHEAT TO WIN
- Does your organization have existing componentes you can use?
  - Do not build a new data warehouse if you already have one.
  - Rebuilding existing technology always has negative business value.
- What is the least amount of infrastrucure you need to built?
  - Import existing data with sqoop or etc if you can.
  - If relaxing a requirement saves a lot of time and money, at least ask.